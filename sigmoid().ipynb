{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+e^(-x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoidprime(x):\n",
    "    return (e^(-x))/(1+e^(-x))^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To make sure that you get the implementation right let us first have a look at the data structure.\n",
    "# These are the four possible input pairs of (x1,x2).\n",
    "x = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "\n",
    "# These are possible labels form some logical gates.\n",
    "tasks = {\n",
    "    t_and : np.array([0,0,0,1])\n",
    "    t_or : np.array([0,1,1,1])\n",
    "    t_nand : np.array([1,1,1,0])\n",
    "    t_nor : np.array([1,0,0,0])\n",
    "    t_xor : np.array([0,1,1,0])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    \n",
    "    def __init__(self, input_units):\n",
    "        self.input_units = input_units\n",
    "        # 1. Initialize random weights and a random bias term. Check 'np.random.randn()'.\n",
    "        self.weights = np.random.randn(input_units)\n",
    "        self.bias = np.random.randn()\n",
    "        # 2. Define the learning rate as 1\n",
    "        self.alpha = 1\n",
    "        #store drive of neuron\n",
    "        self.weighted_sum = 0\n",
    "        \n",
    "    def forward_step(self, input):\n",
    "        # Perform a perceptron forward step.\n",
    "        # 1. Calculate the drive. You can use @ as a matrix multiplication command.\n",
    "        self.weighted_sum =  self.weights @ input + self.bias \n",
    "\n",
    "        # 2. Return activation of Perceptron, depending on whether the perceptron surpassed the threshold. \n",
    "        if self.weighted_sum >= 0:\n",
    "            return sigmoid(self.weighted_sum)\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    \n",
    "    def update(self, delta):\n",
    "        self.bias -= self.alqha * delta\n",
    "        self.weights -= self.alpha * delta * sigmoid(self.weighted_sum)\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class MLP:\n",
    "    def __init__(self):\n",
    "        #Create array with 4 Perceptrons (hidden layer)\n",
    "        self.perceptrons = np.array([Perceptron(2), Perceptron(2), Perceptron(2), Perceptron(2)])\n",
    "        #Create the one read-out Perceptron\n",
    "        self.readout_perceptron = Perceptron(4)\n",
    "        #output of MLP\n",
    "        self.output = 0\n",
    "        \n",
    "        #Storage of values about MLP, loss and accuracy\n",
    "        accuracy = []\n",
    "        loss = []\n",
    "    \n",
    "    def forward_step(self, input):\n",
    "        #Store if Perceptron fires or not, if drive gets above threshold\n",
    "        activation = np.array(4)\n",
    "        #Processing drive\n",
    "        for i in self.perceptrons:\n",
    "            activation[i] = self.perceptrons[i].forward_step(input)\n",
    "        #Storing output of network\n",
    "        self.output = self.readout_perceptron.forward_step(activation)\n",
    "        return \n",
    "        \n",
    "        \n",
    "    def backprop_step(self, task):\n",
    "        \n",
    "        #Calculating label fitting to task\n",
    "        label = label_calc(task)\n",
    "        \n",
    "        #delta calculation for read_out Perceptron\n",
    "        # -(target-activation)*sigmoid'(drive) for l=N (output layer)\n",
    "        readout_perceptron_delta = (label - output)^2 * sigmoidprime(self.readout_perceptron.weighted_sum)\n",
    "        #delta calculation for hidden layer Perceptrons\n",
    "        delta = np.array(4)\n",
    "        for i in delta:\n",
    "            # (sum irrelevant because in this case there is just one perceptron in subsequent layer)\n",
    "            # delta(l+1)*weight(i)(l+1)*sigmoidprime(drive(l))\n",
    "            delta[i] = readout_perceptron_delta * self.readout_perceptron.weights[i] * sigmoidprime(self.perceptrons[i].weighted_sum)\n",
    "        \n",
    "        #calling for updating weights and bias\n",
    "        #1. update output layer\n",
    "        self.readout_perceptron.update(readout_perceptron_delta)\n",
    "        #2. update hidden layer\n",
    "        for i in self.perceptrons:\n",
    "            self.perceptrons[i].update(delta[i])\n",
    "            \n",
    "    def label_calc(self, input, task):\n",
    "        #Calculating corresponding label (1 or 0) for task\n",
    "        index = np.random.randint(len(x))\n",
    "        sample = x[index]\n",
    "        t = tasks[task]\n",
    "        label = t[index]\n",
    "        return [sample, label]\n",
    "    \n",
    "        \n",
    "    def training_step(self, input, task):\n",
    "        accuracy_sum =\n",
    "        \n",
    "        self.forward_step(input)\n",
    "        backprop_step(task)\n",
    "        \n",
    "        loss_sum = label - self.output\n",
    "        \n",
    "        \n",
    "        \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'MLP' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-79-ed9ae83296d2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mtask_choice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"t_and\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"t_or\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"t_nand\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"t_nor\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"t_xor\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m#Create MLP for\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mMLP\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMLP\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;31m#counting steps\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'MLP' object is not callable"
     ]
    }
   ],
   "source": [
    "#Storage of epochs already done, mean accuracy and mean loss\n",
    "epochs = []\n",
    "accuracy_sum = []\n",
    "loss_sum = []\n",
    "\n",
    "task_choice = np.array([\"t_and\", \"t_or\", \"t_nand\", \"t_nor\", \"t_xor\"])\n",
    "#Create MLP for \n",
    "MLP = MLP()\n",
    "#repeat course for 1000 epochs\n",
    "for i in range(1000):\n",
    "    #counting steps\n",
    "    epochs.append(i)\n",
    "    #repeat for every task option\n",
    "    for j in task_choice:\n",
    "        task = j\n",
    "        #execute training for every possible data set in every task option\n",
    "        for k in x:\n",
    "            sample = k\n",
    "            #Do one training step\n",
    "            MLP.training_step(sample, task)\n",
    "            \n",
    "    \n",
    "    \n",
    "    \n",
    "     def label_calc(self,  task):\n",
    "        #Calculating corresponding label (1 or 0) for task\n",
    "        index = np.random.randint(len(x))\n",
    "        sample = x[index]\n",
    "        t = tasks[task]\n",
    "        label = t[index]\n",
    "        return [sample, label]\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "for i in range(7, 15):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
