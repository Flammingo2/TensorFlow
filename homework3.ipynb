{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "homework3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMofWmLtjf3Djf9nNFHoJgP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Flammingo2/TensorFlow/blob/main/homework3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UrcUHVNsOzwG"
      },
      "source": [
        "import numpy as np\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow_datasets as tfds"
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rWZNGySO-Zi",
        "outputId": "6dad63a9-4cea-4a79-df66-21b44e014665",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Load the dataset in Tupel-Format (input, label)\n",
        "train_dataset, test_dataset = tfds.load('genomics_ood', split = ['train[:1%]', 'test[:1%]'], as_supervised=True)\n",
        "\n",
        "train_seq, train_labels = zip(*train_dataset)\n",
        "test_seq, test_labels = zip(*test_dataset)\n",
        "\n",
        "print(train_seq[0])\n",
        "print(train_labels[0])\n",
        "print(train_seq[1])\n",
        "print(train_labels[1])"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(b'AAACTATGTTATATTCACGATGATTAACTTACAAAGGAGTTTCAACTATGAAGATGATAAACAAATTAATCGTTCCGGTAACAGCTAGTGCTTTATTATTAGGCGCTTGTGGCGCTAGTGCCACAGACTCTAAAGAAAATACATTAATTTCTTCTAAAGCTGGAGACGTAACAGTTGCAGATACAATGAAAAAAATCGGTAAAGATCAAATTGCAAATGCATCATTTACTGAAATGTTAAATAAAATTTT', shape=(), dtype=string)\n",
            "tf.Tensor(7, shape=(), dtype=int64)\n",
            "tf.Tensor(b'CACAGCCGGCCGCTGACCTGCTGGCCATCGGAGCGCTGGCCGGCCTCGAGGATATTGGCCAGCAGCAGGTGGATGTCTCGGGCATAGCGCTCCCCCTGGTAGGTGATGCGAATGCTGCGGCCCTGGCGCTCGGTCAGGGCAAAACCCAGGGTCTGCTCCAGGCTCTTGATCTGGTGGCTGATGGCGCTGGGCGTCAGGTTCAGCTCATTGGCGGCCTCGGCGACACTGCCCAGGCGGGCCACCGCGTCCA', shape=(), dtype=string)\n",
            "tf.Tensor(5, shape=(), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-AVxEXj8J2s5",
        "outputId": "2ef9fd3d-3e3e-46b1-af16-50e2eb3eb564",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Look at shapes\n",
        "print(len(train_seq))\n",
        "print(len(train_labels))\n",
        "print(len(test_seq))\n",
        "print(len(test_labels))\n",
        "\n",
        "print(train_labels[0])\n",
        "print(train_seq[0])\n",
        "print(type(train_labels))"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000\n",
            "10000\n",
            "1000\n",
            "1000\n",
            "tf.Tensor(7, shape=(), dtype=int64)\n",
            "tf.Tensor(b'AAACTATGTTATATTCACGATGATTAACTTACAAAGGAGTTTCAACTATGAAGATGATAAACAAATTAATCGTTCCGGTAACAGCTAGTGCTTTATTATTAGGCGCTTGTGGCGCTAGTGCCACAGACTCTAAAGAAAATACATTAATTTCTTCTAAAGCTGGAGACGTAACAGTTGCAGATACAATGAAAAAAATCGGTAAAGATCAAATTGCAAATGCATCATTTACTGAAATGTTAAATAAAATTTT', shape=(), dtype=string)\n",
            "<class 'tuple'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VmtDQP9ZnwAF"
      },
      "source": [
        "def onehotify(tensor):\n",
        "  vocab = {'A':'1', 'C': '2', 'G':'3', 'T':'0'}\n",
        "  for key in vocab.keys():\n",
        "    tensor = tf.strings.regex_replace(tensor, key, vocab[key])\n",
        "  split = tf.strings.bytes_split(tensor)\n",
        "  labels = tf.cast(tf.strings.to_number(split), tf.uint8)\n",
        "  onehot = tf.one_hot(labels, 4)\n",
        "  onehot = tf.reshape(onehot, (-1,))\n",
        "  return onehot"
      ],
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBcV9EPO3Nzf",
        "outputId": "fd8486b0-9943-4174-8af0-1c560fcf956a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "#Create tensors from lists\n",
        "# 1. for training dataset\n",
        "#for sample in train_seq:\n",
        "#  train_seq = onehotify(sample)\n",
        "#train_set_seq = tf.data.Dataset.from_tensor_slices(train_seq)\n",
        "\n",
        "for sample in train_labels:\n",
        "  print(sample.shape)\n",
        "  tf.make_ndarray(sample)\n",
        "  print(sample)\n",
        "  train_labels = sample.map(lambda t : tf.one_hot(t, 10, on_value=1.0, off_value=0.0))\n",
        "print(type(train_labels))\n",
        "print(train_labels[0])\n",
        "train_set_labels = tf.data.Dataset.from_tensor_slices(train_labels)\n",
        "\n",
        "# 2. for test dataset\n",
        "for sample in test_seq:\n",
        "  test_seq = onehotify(sample)\n",
        "test_set_seq = tf.data.Dataset.from_tensor_slices(test_seq)\n",
        "\n",
        "test_labels = test_labels.map(lambda t : tf.one_hot(t,10))\n",
        "test_set_labels = tf.data.Dataset.from_tensor_slices(test_labels)"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "()\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-121-790e31fdaf30>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m   \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_ndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0mtrain_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moff_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36mMakeNdarray\u001b[0;34m(tensor)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m   \"\"\"\n\u001b[0;32m--> 596\u001b[0;31m   \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    597\u001b[0m   \u001b[0mnum_elements\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m   \u001b[0mtensor_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'tensor_shape'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlB28Gk1oUAs"
      },
      "source": [
        "#Reshape to 1D tensors\n",
        "# 1. train dataset\n",
        "train_set_seq = train_seq.map(lambda seq : tf.reshape(seq, (-1,)))\n",
        "train_set_labels = train_set_labels.map(lambda t : tf.one_hot(t, 10))\n",
        "# 2. test dataset\n",
        "test_set_seq = test_set_seq.map(lambda img : tf.reshape(img, (-1,)))\n",
        "test_set_labels = test_set_labels.map(lambda t : tf.one_hot(t,10))\n",
        "\n",
        "#Zip together input images and targets\n",
        "# 1. for training dataset\n",
        "train_dataset = tf.data.Dataset.zip((train_set_seq, train_set_labels)).batch(128).shuffle(buffer_size=128)\n",
        "# 2. for test dataset\n",
        "test_dataset = tf.data.Dataset.zip((test_set_seq, test_set_labels)).batch(128).shuffle(buffer_size=128)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JebsXtF_wnp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}